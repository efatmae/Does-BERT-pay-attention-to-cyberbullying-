This code is the code to excute the experiemnts in the "Does BERT pay attention to cyberbullying?" paper published in Sigir 2021.

The project is organized as follow:
=====================================
Model_Training: contains python files used to train the different models in the paper. 

Model_interpretation: Contains python files used to analyse the attention weights of the trained models and generate the graphs used in the paper.


each folder contains a ReadMe.txt file that explains the content of that folder.

The datasets used in teh paper are availabe in the following links:

Twitter-Racism abd Twitter-Sexism: "Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter".

kaggle-insults: https://www.kaggle.com/c/detecting-insults-in-social-commentary/data.

Wikipedia Talk Pages: Ex Machina: Personal Attacks Seen at Scale.


Disclaimer
==========
While every care has been taken to ensure the accuracy of the data and code provided in this repository, the authors, the University of the West of Scotland, Durham University, and the University of Edinburgh do not provide any guaranties and disclaim all responsibility and all liability (including without limitation, liability in negligence) for all expenses, losses, damages (including indirect or consequential damage) and costs which you might incur as a result of the provided data being inaccurate or incomplete in any way and for any reason. 2021, University of the West of Scotland, Scotland, United Kingdom.

 

Also, put the following reference in the beginning of the readme:
=================================================================
Fatma Elsafoury, Stamos Katsigiannis, Steven R. Wilson, and Naeem Ramzan.2021. Does BERT pay attention to cyberbullying?. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’21), July 11–15, 2021, Virtual Event, Canada. ACM, New York, NY, USA. https://doi.org/10.1145/3404835.3463029
